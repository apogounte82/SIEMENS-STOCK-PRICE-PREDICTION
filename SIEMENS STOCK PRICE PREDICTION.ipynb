{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am going to try to predict the values of Siemens stock price, using a Recurrent Neural Network\n",
    "# We will use data downloaded from the following link\n",
    "# https://finance.yahoo.com/quote/SIE.DE/history?period1=1496696400&period2=1528232400&interval=1d&filter=history&frequency=1d\n",
    "# I have downloaded data of the last 5 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the training set\n",
    "dataset = pd.read_csv('C:\\SIEMENSTRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>78.443001</td>\n",
       "      <td>78.743401</td>\n",
       "      <td>76.970001</td>\n",
       "      <td>77.057297</td>\n",
       "      <td>65.381271</td>\n",
       "      <td>2890421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-07</td>\n",
       "      <td>77.328598</td>\n",
       "      <td>78.278198</td>\n",
       "      <td>76.466103</td>\n",
       "      <td>77.842201</td>\n",
       "      <td>66.047241</td>\n",
       "      <td>3312735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>77.842201</td>\n",
       "      <td>79.014702</td>\n",
       "      <td>77.658096</td>\n",
       "      <td>78.578598</td>\n",
       "      <td>66.672058</td>\n",
       "      <td>2269863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-11</td>\n",
       "      <td>78.142601</td>\n",
       "      <td>78.665802</td>\n",
       "      <td>77.561096</td>\n",
       "      <td>78.472000</td>\n",
       "      <td>66.581604</td>\n",
       "      <td>2501774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>78.384804</td>\n",
       "      <td>78.888702</td>\n",
       "      <td>77.502998</td>\n",
       "      <td>77.822800</td>\n",
       "      <td>66.030785</td>\n",
       "      <td>1937397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume\n",
       "0  2013-06-06  78.443001  78.743401  76.970001  77.057297  65.381271  2890421\n",
       "1  2013-06-07  77.328598  78.278198  76.466103  77.842201  66.047241  3312735\n",
       "2  2013-06-10  77.842201  79.014702  77.658096  78.578598  66.672058  2269863\n",
       "3  2013-06-11  78.142601  78.665802  77.561096  78.472000  66.581604  2501774\n",
       "4  2013-06-12  78.384804  78.888702  77.502998  77.822800  66.030785  1937397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploration\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 7 columns in our dataset, and just by their names it is very clear what they represent\n",
    "# Checking for missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1269 entries, 0 to 1268\n",
      "Data columns (total 7 columns):\n",
      "Date         1269 non-null object\n",
      "Open         1269 non-null object\n",
      "High         1269 non-null object\n",
      "Low          1269 non-null object\n",
      "Close        1269 non-null object\n",
      "Adj Close    1269 non-null object\n",
      "Volume       1269 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 69.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# No missing values, so let's explore a little bit more\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My variable, 'Close', is an \"object\". I will manipulate it accordingly, so that it becomes suitable\n",
    "dataset['Close'] = pd.to_numeric(dataset['Close'] , errors = 'coerce') \n",
    "dataset = dataset.dropna(subset=['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1268 entries, 0 to 1268\n",
      "Data columns (total 7 columns):\n",
      "Date         1268 non-null object\n",
      "Open         1268 non-null object\n",
      "High         1268 non-null object\n",
      "Low          1268 non-null object\n",
      "Close        1268 non-null float64\n",
      "Adj Close    1268 non-null object\n",
      "Volume       1268 non-null object\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 79.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Now let's verify\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So now we are ready to predict. We will try to predict next day's closing stock price,\n",
    "# for the last 30 days, using as a variable, the closing values of the previous 20 days. \n",
    "# I am using the n, because we do not know which timeframe is the most adequate for our purpose\n",
    "# Therefore  I am selecting, the fifth column, \"Close\", name it training_set, and store it\n",
    "# as a numpy array\n",
    "# But first I must exclude the last 30 days of my dataset, because I want them to be\n",
    "# completely unknown, for my prediction , when we get to that point\n",
    "trainset = dataset.iloc[0:1268-30 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can see that the number of rows is 1238, so we have succesfully excluded the last 30days\n",
    "# I am constructing  the training_set, the fifth column of my dataset\n",
    "training_set = trainset.iloc[:, 4:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a data structure with n timesteps and 1 output\n",
    "# I will now crate my X_train and y_train variables, as empty lists at  first.\n",
    "# So, let us say for example, that we will be using the previous 20 days,meaning\n",
    "# values 0 to 19 of our column to predict the 21st, AND next on, days 1-21 to predict\n",
    "# the 22nd, and so on and so forth...Our column has 1238 values\n",
    "X_train = []\n",
    "y_train = []\n",
    "# bazei (20,1238), gt thelei minimum 20 steps.\n",
    "for i in range(20, 1238):\n",
    "    X_train.append(training_set_scaled[i-20:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For instance, if i == 20, it will append to X_train [20-20:20 , 0] -> [0:20, 0]\n",
    "# meaning the first 20 values of our column, and it will append to y_train\n",
    "# [20,0]\n",
    "    \n",
    "# If we leave our X_train = [] and y_train = [] as lists, our RNN will not be able to use them.\n",
    "# twra kanoume tis listes , numpy arrays wste na mporei na tis \n",
    "# dextei to rnn mas\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "\n",
    "# if someone goes to keras documentation, he will see the following:\n",
    "# 3D tensor with shape (batch_size, timesteps, input_dim).\n",
    "# batch size is the total number of rows(observations) we have\n",
    "# timesteps, the number of steps we are willing to take into\n",
    "# consideration, in our case 20\n",
    "# input dim is the number of predictors, in our case just 1, the \n",
    "# 'Close' column\n",
    "# So , we are obligated to reshape our X_train\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the model\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation, to avoid overfitting\n",
    "# units = number of memory units (neurons), need high dimensionality\n",
    "# which is already present due to multiple LSTM layers, but more increased\n",
    "# within each LSTM layer, choosing a correct number of units\n",
    "# return sequences = True, because other layers are following\n",
    "# input shape: Adding the two last \"dimensions\", because the first,corresponding to\n",
    "# the number of observations, is taken into account automatically\n",
    "model.add(LSTM(units = 30, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "# adding 20% dropout , to enhance avoiding of overfitting\n",
    "model.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and again some Dropout regularisation\n",
    "# no need to specify to input shape, automatically recognised\n",
    "model.add(LSTM(units = 30, return_sequences = True))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and  Dropout \n",
    "model.add(LSTM(units = 30, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and Dropout \n",
    "model.add(LSTM(units = 30, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a fifth LSTM layer and some Dropout regularisation\n",
    "# default return sequences is false, and beacuse there is not a next\n",
    "# LSTM layer, we omit referring to it\n",
    "model.add(LSTM(units = 30))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1218/1218 [==============================] - 11s 9ms/step - loss: 0.0612\n",
      "Epoch 2/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0114\n",
      "Epoch 3/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0090\n",
      "Epoch 4/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0084\n",
      "Epoch 5/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0082\n",
      "Epoch 6/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0082\n",
      "Epoch 7/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0083\n",
      "Epoch 8/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0086\n",
      "Epoch 9/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0077\n",
      "Epoch 10/100\n",
      "1218/1218 [==============================] - 5s 4ms/step - loss: 0.0071\n",
      "Epoch 11/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 12/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0072\n",
      "Epoch 13/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0070\n",
      "Epoch 14/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0067\n",
      "Epoch 15/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 16/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0072\n",
      "Epoch 17/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 18/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0069\n",
      "Epoch 19/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 20/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 21/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 22/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 23/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0055\n",
      "Epoch 24/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 25/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 26/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 27/100\n",
      "1218/1218 [==============================] - 4s 4ms/step - loss: 0.0054\n",
      "Epoch 28/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 29/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0052\n",
      "Epoch 30/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 31/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0056\n",
      "Epoch 32/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0048\n",
      "Epoch 33/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0053\n",
      "Epoch 34/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 35/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0050\n",
      "Epoch 36/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0045\n",
      "Epoch 37/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0051\n",
      "Epoch 38/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0049\n",
      "Epoch 39/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0042\n",
      "Epoch 40/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0045\n",
      "Epoch 41/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0044\n",
      "Epoch 42/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0041A: 0s - los\n",
      "Epoch 43/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0042\n",
      "Epoch 44/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0040\n",
      "Epoch 45/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0040\n",
      "Epoch 46/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 47/100\n",
      "1218/1218 [==============================] - 4s 4ms/step - loss: 0.0041A: 1s -\n",
      "Epoch 48/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0037\n",
      "Epoch 49/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0036\n",
      "Epoch 50/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0035\n",
      "Epoch 51/100\n",
      "1218/1218 [==============================] - 5s 4ms/step - loss: 0.0035\n",
      "Epoch 52/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 53/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 54/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0035\n",
      "Epoch 55/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0033\n",
      "Epoch 56/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0039\n",
      "Epoch 57/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0033\n",
      "Epoch 58/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0030\n",
      "Epoch 59/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0031\n",
      "Epoch 60/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0032\n",
      "Epoch 61/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0031\n",
      "Epoch 62/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0029\n",
      "Epoch 63/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0031\n",
      "Epoch 64/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0030\n",
      "Epoch 65/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0028\n",
      "Epoch 66/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0028\n",
      "Epoch 67/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0029\n",
      "Epoch 68/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0027\n",
      "Epoch 69/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0026\n",
      "Epoch 70/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0026\n",
      "Epoch 71/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0025\n",
      "Epoch 72/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0027\n",
      "Epoch 73/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0025\n",
      "Epoch 74/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0024\n",
      "Epoch 75/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0026\n",
      "Epoch 76/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0030\n",
      "Epoch 77/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0025\n",
      "Epoch 78/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0026\n",
      "Epoch 79/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0024\n",
      "Epoch 80/100\n",
      "1218/1218 [==============================] - 4s 4ms/step - loss: 0.0025\n",
      "Epoch 81/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0024\n",
      "Epoch 82/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0024\n",
      "Epoch 83/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0025A: 0s - loss:\n",
      "Epoch 84/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0021\n",
      "Epoch 85/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0021A: 0s - loss: 0.\n",
      "Epoch 86/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0022\n",
      "Epoch 87/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0022\n",
      "Epoch 88/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0022\n",
      "Epoch 89/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0022\n",
      "Epoch 90/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 91/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0019\n",
      "Epoch 92/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0019\n",
      "Epoch 93/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0022\n",
      "Epoch 94/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 95/100\n",
      "1218/1218 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 97/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 98/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0019\n",
      "Epoch 99/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 100/100\n",
      "1218/1218 [==============================] - 4s 3ms/step - loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x102aa208>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the output layer,units is set to 1, becaue we are\n",
    "# trying to predict one thing, the stock price\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "# we could use either  adam or rmsprop\n",
    "# the loss function is mean squared error, because in fact, it is a regression\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Very low loss, so we are expecting a good prediction\n",
    "# I will use the last 30 days of my dataset, plus the previous 20, to try to predict the price\n",
    "# Meaning I am creating the dataset_test dataframe, using the last 50 rows, and all the columns.\n",
    "dataset_test = dataset.iloc[1268-30-20:1268 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am going to set a variable, real_stock_price, meaning the last 30 days of my dataset test\n",
    "# because next on I will be using it for visualisation along with the predicted price\n",
    "real_stock_price = dataset_test.iloc[20:50, 4:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now , I must transform, the 5th column, \"Close\", of dataset_test dataframe\n",
    "# into an array.\n",
    "testing = dataset_test.iloc[: , 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am also using reshape on my testing variable, because I must have a suitable form of my array\n",
    "# After applying it, we can see two [[]], which makes it adequate for my purpose\n",
    "testing = testing.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Of course , we must apply once again SCALING \n",
    "testing = sc.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now I will construct the X_test. I will get all the last 30 lines of my testing array\n",
    "# starting from the 21st day, because I need to have at least 20 previous days for prediction\n",
    "# Following the same procedure, I am creating an empty list called X_test\n",
    "X_test = []\n",
    "for i in range(20, 50):\n",
    "    X_test.append(testing[i-20:i, 0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turning it into an array\n",
    "X_test = np.array(X_test)\n",
    "# We must not forget to reshape it , as directed by the keras documentation\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the results\n",
    "predicted_stock_price = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inversing the predicted results. Otherwise they will be scaled and not comparable to\n",
    "# the real stock price\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYmkBCEiIpGUIEREJNL/AMgCPAEXT+tZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16725dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Siemens Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Siemens Stock Price')\n",
    "plt.title('Siemens Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Siemens Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comments\n",
    "\n",
    "# Our line, is smoother than the real , and of course it cannot predict \n",
    "# sudden changes like for instance day 6 or day 19.  Still, it depicts\n",
    "# quite well the \"trend\" of the stock price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
